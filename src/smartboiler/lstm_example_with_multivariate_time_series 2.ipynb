{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EPkQkTqhjabZ"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DBL1nFtWjaba"
   },
   "source": [
    "# Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FLzogEmbjabc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adamgrunwald/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "dlopen(/Users/adamgrunwald/Library/Python/3.9/lib/python/site-packages/tensorflow-plugins/libmetal_plugin.dylib, 0x0006): symbol not found in flat namespace '__ZN10tensorflow8internal10LogMessage16VmoduleActivatedEPKci'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mean_squared_error\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#keras version\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(keras\u001b[38;5;241m.\u001b[39m__version__)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential \n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/keras/__init__.py:10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Import everything from /api/ into keras.\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__  \u001b[38;5;66;03m# Import * ignores names start with \"_\".\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Add everything in /api/ to the module search path.\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/keras/api/__init__.py:8\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"DO NOT EDIT.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mThis file was autogenerated. Do not edit it by hand,\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03msince your modifications would be overwritten.\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m activations\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m applications\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/keras/api/activations/__init__.py:7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"DO NOT EDIT.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mThis file was autogenerated. Do not edit it by hand,\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03msince your modifications would be overwritten.\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deserialize\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m serialize\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/keras/src/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m activations\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m applications\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/keras/src/activations/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtypes\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m elu\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m exponential\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gelu\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/keras/src/activations/activations.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ops\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi_export\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras_export\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/keras/src/backend/__init__.py:9\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# When using the torch backend,\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# torch needs to be imported first, otherwise it will segfault\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# upon import.\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m result_type\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras_tensor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KerasTensor\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras_tensor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m any_symbolic_tensors\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/keras/src/backend/common/__init__.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend_utils\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m result_type\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvariables\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutocastScope\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvariables\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KerasVariable\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/keras/src/backend/common/dtypes.py:5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi_export\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras_export\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvariables\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m standardize_dtype\n\u001b[1;32m      7\u001b[0m BOOL_TYPES \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbool\u001b[39m\u001b[38;5;124m\"\u001b[39m,)\n\u001b[1;32m      8\u001b[0m INT_TYPES \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muint8\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muint16\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mint64\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     17\u001b[0m )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/keras/src/backend/common/variables.py:10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstateless_scope\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_stateless_scope\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstateless_scope\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m in_stateless_scope\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodule_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tensorflow \u001b[38;5;28;01mas\u001b[39;00m tf\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnaming\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m auto_name\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mKerasVariable\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/keras/src/utils/__init__.py:12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m enable_interactive_logging\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_interactive_logging_enabled\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_visualization\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m model_to_dot\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_visualization\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m plot_model\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumerical_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m normalize\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/keras/src/utils/model_visualization.py:6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tree\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi_export\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras_export\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m io_utils\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/keras/src/tree/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtree\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtree_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m assert_same_structure\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtree\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtree_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m flatten\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtree\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtree_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_nested\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/keras/src/tree/tree_api.py:6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodule_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m optree\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m optree\u001b[38;5;241m.\u001b[39mavailable:\n\u001b[0;32m----> 6\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtree\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m optree_impl \u001b[38;5;28;01mas\u001b[39;00m tree_impl\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m dmtree\u001b[38;5;241m.\u001b[39mavailable:\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtree\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dmtree_impl \u001b[38;5;28;01mas\u001b[39;00m tree_impl\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/keras/src/tree/optree_impl.py:17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Register backend-specific node classes\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensorflow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 17\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrackable\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_structures\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ListWrapper\n\u001b[1;32m     19\u001b[0m     optree\u001b[38;5;241m.\u001b[39mregister_pytree_node(\n\u001b[1;32m     20\u001b[0m         ListWrapper,\n\u001b[1;32m     21\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m x: (x, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m     22\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m metadata, children: ListWrapper(\u001b[38;5;28mlist\u001b[39m(children)),\n\u001b[1;32m     23\u001b[0m         namespace\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     24\u001b[0m     )\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_nested\u001b[39m(structure):\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/__init__.py:432\u001b[0m\n\u001b[1;32m    430\u001b[0m _plugin_dir \u001b[38;5;241m=\u001b[39m _os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(_s, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensorflow-plugins\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    431\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(_plugin_dir):\n\u001b[0;32m--> 432\u001b[0m   \u001b[43m_ll\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_library\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_plugin_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    433\u001b[0m   \u001b[38;5;66;03m# Load Pluggable Device Library\u001b[39;00m\n\u001b[1;32m    434\u001b[0m   _ll\u001b[38;5;241m.\u001b[39mload_pluggable_device_library(_plugin_dir)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/python/framework/load_library.py:151\u001b[0m, in \u001b[0;36mload_library\u001b[0;34m(library_location)\u001b[0m\n\u001b[1;32m    148\u001b[0m     kernel_libraries \u001b[38;5;241m=\u001b[39m [library_location]\n\u001b[1;32m    150\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m lib \u001b[38;5;129;01min\u001b[39;00m kernel_libraries:\n\u001b[0;32m--> 151\u001b[0m     \u001b[43mpy_tf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTF_LoadLibrary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlib\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    154\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[1;32m    155\u001b[0m       errno\u001b[38;5;241m.\u001b[39mENOENT,\n\u001b[1;32m    156\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe file or folder to load kernel libraries from does not exist.\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    157\u001b[0m       library_location)\n",
      "\u001b[0;31mNotFoundError\u001b[0m: dlopen(/Users/adamgrunwald/Library/Python/3.9/lib/python/site-packages/tensorflow-plugins/libmetal_plugin.dylib, 0x0006): symbol not found in flat namespace '__ZN10tensorflow8internal10LogMessage16VmoduleActivatedEPKci'"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "#keras version\n",
    "import keras\n",
    "print(keras.__version__)\n",
    "from keras.models import Sequential \n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import keras.backend as K\n",
    "import pickle \n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from math import dist\n",
    "import numpy as np\n",
    "from geopy.distance import geodesic\n",
    "from haversine import haversine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def haversine_dist(x1,x2,y1,y2):\n",
    "   return haversine((x1, x2) , (y1, y2), unit='km')\n",
    "\n",
    "# Data Processing \n",
    "\n",
    "\n",
    "\n",
    "def extract_features_from_longitude_latitude(df_old, home_longitude, home_latitude):\n",
    "        df = df_old.copy()        \n",
    "        df = df.dropna(subset=[\"mean_latitude\", \"mean_longitude\"])\n",
    "\n",
    "        df.loc[:,\"distance_from_home\"] = np.vectorize(haversine_dist)(\n",
    "            df[\"mean_latitude\"],\n",
    "            df[\"mean_longitude\"],\n",
    "            home_latitude,\n",
    "            home_longitude,\n",
    "        )\n",
    "\n",
    "        df.loc[:,\"heading_to_home\"] = np.arctan2(\n",
    "            df[\"mean_latitude\"] - home_latitude,\n",
    "            df[\"mean_longitude\"] - home_longitude,\n",
    "        )\n",
    "        df.loc[:,\"heading_to_home_sin\"] = np.sin(df[\"heading_to_home\"])\n",
    "        df.loc[:,\"heading_to_home_cos\"] = np.cos(df[\"heading_to_home\"])\n",
    "        # resample by 10m mean\n",
    "        df.loc[:,\"time_stamp\"] = df.index\n",
    "        # calculate the speed of device\n",
    "        df.loc[:,\"time_diff\"] = (\n",
    "            df[\"time_stamp\"].diff().dt.total_seconds() / 3600\n",
    "        )  # Convert seconds to hours\n",
    "        df.loc[:,\"distance\"] = np.vectorize(haversine_dist)(\n",
    "            df[\"mean_latitude\"],\n",
    "            df[\"mean_longitude\"],\n",
    "            df[\"mean_latitude\"].shift(1),\n",
    "            df[\"mean_longitude\"].shift(1),\n",
    "        )  # calculate haversine distance\n",
    "        # df['hours'] = (df['time_stamp'].astype(int) / 10**9) / 60*60 # convert to seconds\n",
    "        # df['time_taken'] = df['hours'] - df['hours'].shift(1) # calculate time difference\n",
    "\n",
    "        df.loc[:,\"speed\"] = df[\"distance\"] / df[\"time_diff\"]  # cal speed\n",
    "        df.loc[ df[\"speed\"] > 200, \"speed\"] = 0\n",
    "        df.loc[:,\"speed_towards_home\"] = df[\"speed\"] * df[\"heading_to_home_cos\"]\n",
    "        return df\n",
    "\n",
    "# df = df.resample('10T').mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from influxdb import DataFrameClient\n",
    "import pandas as pd\n",
    "db_name_zuka = 'smart_home_zukalovi'\n",
    "dataframe_client_zuka = DataFrameClient(\n",
    "            host='localhost',\n",
    "            port=8086,\n",
    "            username='root',\n",
    "            password='root',\n",
    "            database='smart_home_zukalovi',\n",
    "        )\n",
    "\n",
    "left_time_interval = pd.to_datetime('2023-10-01 00:00:00')\n",
    "right_time_interval = pd.to_datetime('2024-04-22 15:00:00')\n",
    "left_time_interval = f\"'{left_time_interval.strftime('%Y-%m-%dT%H:%M:%SZ')}'\"\n",
    "right_time_interval = f\"'{right_time_interval.strftime('%Y-%m-%dT%H:%M:%SZ')}'\"\n",
    "group_by_time_interval = '10s'\n",
    "tmp_output_water_entity_id_zuka = 'esphome_web_c771e8_ntc_temperature_b_constant'\n",
    "tmp_output_water_entity_id_2_zuka = 'esphome_web_c771e8_ntc_temperature_b_constant_2'\n",
    "tmp_boiler_case_entity_id_zuka = 'esphome_web_c771e8_tmp3'\n",
    "relay_entity_id_zuka = 'shelly1pm_84cca8b07eae'\n",
    "device_tracker_entity_zuka = 'klara_z_iphone'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "dataframe_client_form = DataFrameClient(\n",
    "            host='localhost',\n",
    "            port=8086,\n",
    "            username='root',\n",
    "            password='root',\n",
    "            database='smart_home_formankovi',\n",
    "        )\n",
    "db_name_form = 'smart_home_formankovi'\n",
    "tmp_output_water_entity_id_form = 'esphome_boiler_temps_ntc_temperature_b_constant'\n",
    "tmp_output_water_entity_id_2_form = 'esphome_web_b7a7f1_ntc_temperature_b_constant'\n",
    "tmp_boiler_case_entity_id_form = 'shelly1pm_34945475a969_temperature_2'\n",
    "relay_entity_id_form = 'shelly1pm_34945475a969'\n",
    "device_tracker_entity_form = 'rmx3085'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "\n",
    "# format datetime to YYYY-MM-DDTHH:MM:SSZ\n",
    "\n",
    "\n",
    "def get_queries(db_name, left_time_interval, right_time_interval, group_by_time_interval, tmp_output_water_entity_id, tmp_output_water_entity_id_2, tmp_boiler_case_entity_id, relay_entity_id, device_tracker_entity):\n",
    "\n",
    "    return {\n",
    "        \"water_flow\": {\n",
    "            \"sql_query\": f'SELECT mean(\"value\") AS \"water_flow_L_per_minute_mean\" FROM \"{db_name}\".\"autogen\".\"L/min\" WHERE time > {left_time_interval} AND time < {right_time_interval} GROUP BY time({group_by_time_interval}) FILL(0)',\n",
    "            \"measurement\": \"L/min\",\n",
    "        },\n",
    "        \"water_temperature\": {\n",
    "            \"sql_query\": f'SELECT mean(\"value\") AS \"water_temperature_mean\" FROM \"{db_name}\".\"autogen\".\"째C\" WHERE time > {left_time_interval} AND time < {right_time_interval} AND (\"entity_id\"=\\'{tmp_output_water_entity_id}\\' OR \"entity_id\"=\\'{tmp_output_water_entity_id_2}\\') GROUP BY time({group_by_time_interval}) FILL(0)',\n",
    "            \"measurement\": \"째C\",\n",
    "        },\n",
    "        \"temperature\": {\n",
    "            \"sql_query\": f'SELECT mean(\"temperature\") AS \"outside_temperature_mean\" FROM \"{db_name}\".\"autogen\".\"state\" WHERE time > {left_time_interval} AND time < {right_time_interval} AND \"domain\"=\\'weather\\' AND \"entity_id\"=\\'domov\\' GROUP BY time({group_by_time_interval}) FILL(null)',\n",
    "            \"measurement\": \"state\",\n",
    "        },\n",
    "        \"humidity\": {\n",
    "            \"sql_query\": f'SELECT mean(\"humidity\") AS \"outside_humidity_mean\" FROM \"{db_name}\".\"autogen\".\"state\" WHERE time > {left_time_interval} AND time < {right_time_interval} AND \"domain\"=\\'weather\\' AND \"entity_id\"=\\'domov\\' GROUP BY time({group_by_time_interval}) FILL(null)',\n",
    "            \"measurement\": \"state\",\n",
    "        },\n",
    "        \"wind_speed\": {\n",
    "            \"sql_query\": f'SELECT mean(\"wind_speed\") AS \"outside_wind_speed_mean\" FROM \"{db_name}\".\"autogen\".\"state\" WHERE time > {left_time_interval} AND time < {right_time_interval} AND \"entity_id\"=\\'domov\\' GROUP BY time({group_by_time_interval}) FILL(null)',\n",
    "            \"measurement\": \"state\",\n",
    "        },\n",
    "        \"presence\": {\n",
    "            \"sql_query\": f'SELECT count(distinct(\"friendly_name_str\")) AS \"device_presence_distinct_count\" FROM \"{db_name}\".\"autogen\".\"state\" WHERE time > {left_time_interval} AND time < {right_time_interval} AND \"domain\"=\\'device_tracker\\' AND \"state\"=\\'home\\' GROUP BY time({group_by_time_interval}) FILL(0)',\n",
    "            \"measurement\": \"state\",\n",
    "        },\n",
    "        \"boiler_water_temperature\": {\n",
    "            \"sql_query\": f'SELECT mean(\"value\") AS \"boiler_water_temperature_mean\" FROM \"{db_name}\".\"autogen\".\"째C\" WHERE time > {left_time_interval} AND time < {right_time_interval} AND \"entity_id\"=\\'{tmp_boiler_case_entity_id}\\' GROUP BY time({group_by_time_interval}) FILL(null)',\n",
    "            \"measurement\": \"째C\",\n",
    "        },\n",
    "        \"boiler_relay_status\": {\n",
    "            \"sql_query\": f'SELECT last(\"value\") AS \"boiler_relay_status\" FROM \"{db_name}\".\"autogen\".\"state\" WHERE time > {left_time_interval} AND time < {right_time_interval} AND \"entity_id\"=\\'{relay_entity_id}\\' GROUP BY time({group_by_time_interval}) FILL(null)',\n",
    "            \"measurement\": \"state\",\n",
    "        },\n",
    "        \"device_longitude\": {\n",
    "            \"sql_query\": f'SELECT mean(\"longitude\") AS \"mean_longitude\" FROM \"{db_name}\".\"autogen\".\"state\" WHERE time > {left_time_interval} AND time < {right_time_interval} AND \"domain\"=\\'device_tracker\\' AND \"entity_id\"=\\'{device_tracker_entity}\\' GROUP BY time({group_by_time_interval}) FILL(previous)',\n",
    "            \"measurement\": \"state\",\n",
    "        },\n",
    "        \"device_latitude\": {\n",
    "            \"sql_query\": f'SELECT mean(\"latitude\") AS \"mean_latitude\" FROM \"{db_name}\".\"autogen\".\"state\" WHERE time > {left_time_interval} AND time < {right_time_interval} AND \"domain\"=\\'device_tracker\\' AND \"entity_id\"=\\'{device_tracker_entity}\\' GROUP BY time({group_by_time_interval}) FILL(previous)',\n",
    "            \"measurement\": \"state\",\n",
    "        },\n",
    "        \n",
    "    } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "df_all_list = []\n",
    "\n",
    "for key, value in get_queries(db_name = db_name_form, left_time_interval = left_time_interval, right_time_interval = right_time_interval, group_by_time_interval = group_by_time_interval, tmp_output_water_entity_id = tmp_output_water_entity_id_form, tmp_output_water_entity_id_2 = tmp_output_water_entity_id_2_form, tmp_boiler_case_entity_id = tmp_boiler_case_entity_id_form, relay_entity_id = relay_entity_id_form, device_tracker_entity = device_tracker_entity_form).items():\n",
    "    print(\"Querying: \", key, value[\"sql_query\"])\n",
    "    # get data from influxdb\n",
    "    result = dataframe_client_form.query(value[\"sql_query\"])[\n",
    "        value[\"measurement\"]\n",
    "    ]\n",
    "\n",
    "    df = pd.DataFrame(result)\n",
    "    \n",
    "    df_all_list.append(df)\n",
    "\n",
    "df_concat_form = pd.concat(df_all_list, axis=1)\n",
    "# save as pkl\n",
    "with open('df_form_mult_22042024.pkl', 'wb') as f:\n",
    "    df_concat_form.to_pickle(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "df_all_list = []\n",
    "    # iterate over key an value in data\n",
    "for key, value in get_queries(db_name=db_name_zuka, left_time_interval=left_time_interval, right_time_interval=right_time_interval, group_by_time_interval='10s', tmp_output_water_entity_id=tmp_output_water_entity_id_2_zuka, tmp_output_water_entity_id_2=tmp_output_water_entity_id_zuka, tmp_boiler_case_entity_id=tmp_boiler_case_entity_id_zuka, relay_entity_id=relay_entity_id_zuka, device_tracker_entity=device_tracker_entity_zuka).items():\n",
    "    print(\"Querying: \", key, value[\"sql_query\"])\n",
    "    # get data from influxdb\n",
    "    result = dataframe_client_zuka.query(value[\"sql_query\"])[\n",
    "        value[\"measurement\"]\n",
    "    ]\n",
    "\n",
    "    df = pd.DataFrame(result)\n",
    "    \n",
    "    df_all_list.append(df)\n",
    "\n",
    "df_concat_zuka = pd.concat(df_all_list, axis=1)\n",
    "# save as pkl\n",
    "with open('df_zuka_mult_22042024.pkl', 'wb') as f:\n",
    "    df_concat_zuka.to_pickle(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "#load df form pkl\n",
    "with open('df_form_mult_22042024.pkl', 'rb') as f:\n",
    "    df_concat_form = pickle.load(f)\n",
    "    df_concat_form = df_concat_form.dropna(subset=['water_temperature_mean'])\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "with open('df_zuka_mult_22042024.pkl', 'rb') as f:\n",
    "    df_concat_zuka = pickle.load(f)\n",
    "    df_concat_zuka = df_concat_zuka.dropna(subset=['water_temperature_mean'])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "#49.412897925874184, 16.514843458109933\n",
    "zuka_home_longitude = 16.514843458109933\n",
    "zuka_home_latitude = 49.412897925874184\n",
    "df_copy_zuka = df_concat_zuka.copy()\n",
    "df_extracted_zuka = extract_features_from_longitude_latitude(df_copy_zuka, home_longitude=zuka_home_longitude, home_latitude=zuka_home_latitude)\n",
    "# all value in speed larger than 200 set to 0\n",
    "df_extracted_zuka.loc[df_extracted_zuka['speed'] > 200, 'speed'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "\n",
    "    \n",
    "\n",
    "# 49.39534649920643, 16.527887919743097\n",
    "form_home_longitude = 16.527887919743097\n",
    "form_home_latitude = 49.39534649920643\n",
    "\n",
    "df_copy_form = df_concat_form.copy()\n",
    "df_extracted_form = extract_features_from_longitude_latitude(df_copy_form, home_longitude=form_home_longitude, home_latitude=form_home_latitude)\n",
    "# all value in speed larger than 200 set to 0\n",
    "df_extracted_form.loc[df_extracted_form['speed'] > 200, 'speed'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from data_handler import DataHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "left_time_interval = pd.to_datetime(\"2023-10-01 00:00:00\")\n",
    "right_time_interval = pd.to_datetime(\"2024-3-16 15:00:00\")\n",
    "left_time_interval = f\"'{left_time_interval.strftime('%Y-%m-%dT%H:%M:%SZ')}'\"\n",
    "right_time_interval = f\"'{right_time_interval.strftime('%Y-%m-%dT%H:%M:%SZ')}'\"\n",
    "group_by_time_interval = \"10s\"\n",
    "tmp_output_water_entity_id_zuka = \"esphome_web_c771e8_ntc_temperature_b_constant\"\n",
    "tmp_output_water_entity_id_2_zuka = \"esphome_web_c771e8_ntc_temperature_b_constant_2\"\n",
    "tmp_boiler_case_entity_id_zuka = \"esphome_web_c771e8_tmp3\"\n",
    "relay_entity_id_zuka = \"shelly1pm_84cca8b07eae\"\n",
    "relay_power_entity_id_zuka = \"shelly1pm_84cca8b07eae_power\"\n",
    "device_tracker_entity_zuka = \"klara_z_iphone\"\n",
    "device_tracker_entity_zuka_2 = \"anezka_iphone\"\n",
    "\n",
    "\n",
    "dataHandlerZuka = DataHandler(\n",
    "    \"localhost\", \"smart_home_zukalovi\", \"root\", \"root\", relay_entity_id_zuka, relay_power_entity_id_zuka, tmp_boiler_case_entity_id_zuka, tmp_output_water_entity_id_zuka, tmp_output_water_entity_id_2_zuka, device_tracker_entity_zuka,device_tracker_entity_zuka_2, zuka_home_longitude, zuka_home_latitude\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "db_name_form = 'smart_home_formankovi'\n",
    "tmp_output_water_entity_id_form = 'esphome_boiler_temps_ntc_temperature_b_constant'\n",
    "tmp_output_water_entity_id_2_form = 'esphome_web_b7a7f1_ntc_temperature_b_constant'\n",
    "tmp_boiler_case_entity_id_form = 'shelly1pm_34945475a969_temperature_2'\n",
    "relay_entity_id_form = 'shelly1pm_34945475a969'\n",
    "relay_power_entity_id_form = 'shelly1pm_34945475a969_power'\n",
    "device_tracker_entity_form = 'rmx3085'\n",
    "device_tracker_entity_form_2 = 'rmx3085'\n",
    "\n",
    "dataHandlerForm = DataHandler(\n",
    "    \"localhost\", db_name_form, \"root\", \"root\", relay_entity_id_form, relay_power_entity_id_form, tmp_boiler_case_entity_id_form, tmp_output_water_entity_id_form, tmp_output_water_entity_id_2_form, device_tracker_entity_form, device_tracker_entity_form_2, form_home_longitude, form_home_latitude\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "\n",
    "# data_processed_zuka = dataHandlerZuka.process_kWh_water_consumption(df_extracted_zuka)\n",
    "# data_processed_zuka_ml = dataHandlerZuka.transform_data_for_ml(data_processed_zuka)\n",
    "# ml_data_zuka = data_processed_zuka_ml[0]\n",
    "\n",
    "ml_data_zuka, datetimes_zuka = dataHandlerZuka.get_data_for_prediction(datetime(2023, 10, 1, 0, 0, 0), datetime(2024, 4, 22, 0, 0, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# data_processed_form = dataHandlerForm.process_kWh_water_consumption(df_extracted_form)\n",
    "# data_processed_form_ml = dataHandlerForm.transform_data_for_ml(data_processed_form)\n",
    "# ml_data_form = data_processed_form_ml[0]\n",
    "\n",
    "ml_data_form, datetimes_form = dataHandlerForm.get_data_for_prediction(datetime(2023, 10, 1, 0, 0, 0), datetime(2024, 4, 22, 0, 0, 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "ml_data_form_datetimes = ml_data_form.copy()\n",
    "ml_data_form_datetimes.index = datetimes_form\n",
    "\n",
    "ml_data_zuka_datetimes = ml_data_zuka.copy()\n",
    "ml_data_zuka_datetimes.index = datetimes_zuka\n",
    "\n",
    "\n",
    "\n",
    "# replace nan humidity, temeprature and wind_speed with values with same index from ml_data_zuka\n",
    "ml_data_form_datetimes['temperature'] = ml_data_form_datetimes['temperature'].combine_first(ml_data_zuka_datetimes['temperature'])\n",
    "ml_data_form_datetimes['humidity'] = ml_data_form_datetimes['humidity'].combine_first(ml_data_zuka_datetimes['humidity'])\n",
    "ml_data_form_datetimes['wind_speed'] = ml_data_form_datetimes['wind_speed'].combine_first(ml_data_zuka_datetimes['wind_speed'])\n",
    "\n",
    "# ffill this values\n",
    "ml_data_form_datetimes['temperature'] = ml_data_form_datetimes['temperature'].ffill()\n",
    "ml_data_form_datetimes['humidity'] = ml_data_form_datetimes['humidity'].ffill()\n",
    "ml_data_form_datetimes['wind_speed'] = ml_data_form_datetimes['wind_speed'].ffill()\n",
    "ml_data_form = ml_data_form_datetimes.reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T7BQqFjcjab7"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "##FOR\n",
    "df_form = ml_data_form.reset_index(drop=True).copy()\n",
    "#60T\n",
    "df_60T_form = pd.concat([df_form.iloc[0:1500]])\n",
    "\n",
    "with open('df_60T_form.pkl', 'wb') as f:\n",
    "    df_60T_form.to_pickle(f)\n",
    "\n",
    "#d\n",
    "df_form = df_60T_form.reset_index(drop=True).copy()\n",
    "# drop rows where last_3_week_skew is nan\n",
    "df_form = df_form.dropna(subset=['last_3_week_skew'])\n",
    "# reduce distance greater than 50\n",
    "df_form['distance_from_home'] = df_form['distance_from_home'].apply(lambda x: x if x < 50 else 50)\n",
    "# df_form['distance_from_home_2'] = df_form['distance_from_home_2'].apply(lambda x: x if x < 50 else 50)\n",
    "df_train_form = df_form.loc[:int(df_form.shape[0]*0.8),:]\n",
    "df_test_form = df_form.loc[int(df_form.shape[0]*0.8):,:]\n",
    "\n",
    "# ## ZUKA\n",
    "\n",
    "df_zuka = ml_data_zuka.reset_index(drop=True).copy()\n",
    "df_form.plot(y='count')\n",
    "\n",
    "#60T\n",
    "df_60T_zuka = pd.concat([df_zuka.iloc[900:1400], df_zuka.iloc[1900:]])\n",
    "with open('df_60T_zuka.pkl', 'wb') as f:\n",
    "    df_60T_zuka.to_pickle(f)\n",
    "\n",
    "df_zuka = df_60T_zuka.reset_index(drop=True).copy()\n",
    "# df_zuka['distance_from_home_2'] = df_zuka['distance_from_home_2'].apply(lambda x: x if x < 30 else 30)\n",
    "df_zuka['distance_from_home'] = df_zuka['distance_from_home'].apply(lambda x: x if x < 30 else 30)\n",
    "df_train_zuka = df_zuka.loc[:int(df_zuka.shape[0]*0.8),:]\n",
    "df_test_zuka = df_zuka.loc[int(df_zuka.shape[0]*0.8):,:]\n",
    "\n",
    "\n",
    "# df = df_60T.reset_index(drop=True).dropna()\n",
    "\n",
    "df_train = pd.concat([df_train_form, df_train_zuka]).reset_index(drop=True).dropna()\n",
    "df_test = pd.concat([df_test_form, df_test_zuka]).reset_index(drop=True).dropna()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "#plot df_form longtime_mean\n",
    "df_zuka['distance_from_home'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "df_plot = df_train.copy()\n",
    "df_plot = df_plot[-168:]\n",
    "# create a plots with longitme mean, distance_from_home, speed_towards_home and count\n",
    "# import mdates\n",
    "import matplotlib.dates as mdates\n",
    "fig, axs = plt.subplots(4, 1, figsize=(20, 20))\n",
    "# create an index as a time with start 11.11.2023, duration one week by 1h\n",
    "df_plot['time'] = pd.date_range(start='11/11/2023', periods=len(df_plot), freq='H')\n",
    "\n",
    "# show x labels as DD. MM. YYYY\n",
    "axs[0].xaxis.set_major_formatter(mdates.DateFormatter('%d. %m. %Y'))\n",
    "axs[1].xaxis.set_major_formatter(mdates.DateFormatter('%d. %m. %Y'))\n",
    "axs[2].xaxis.set_major_formatter(mdates.DateFormatter('%d. %m. %Y'))\n",
    "axs[3].xaxis.set_major_formatter(mdates.DateFormatter('%d. %m. %Y'))\n",
    "df_plot = df_plot.set_index('time')\n",
    "\n",
    "axs[0].plot(df_plot['longtime_mean'], label='longtime_mean', linewidth=2)\n",
    "# axs[0].set_title('Spoteba tepla za hodinu')\n",
    "#set y axis label\n",
    "axs[0].set_ylabel('Spoteba [kWh]')\n",
    "axs[0].legend(['Spoteba tepla za hodinu'])\n",
    "\n",
    "axs[1].plot(df_plot['distance_from_home'], label='distance_from_home', linewidth=2)\n",
    "# axs[1].set_title('Vzd찼lenost od domova')\n",
    "axs[1].set_ylabel('Vzd찼lenost [km]')\n",
    "axs[1].legend(['Vzd찼lenost od domova'])\n",
    "\n",
    "axs[2].plot(df_plot['speed_towards_home'], label='speed_towards_home', linewidth=2)\n",
    "# axs[2].set_title('Rychlost smrem k domovu')\n",
    "axs[2].set_ylabel('Rychlost [km/h]')\n",
    "axs[2].legend(['Rychlost smrem k domovu'])\n",
    "\n",
    "axs[3].plot(df_plot['count'], label='count', linewidth=2)\n",
    "# axs[3].set_title('Poet za챠zen챠 pipojen첵ch k Wi-Fi')\n",
    "#set label\n",
    "axs[3].set_ylabel('Poet', fontsize=20)\n",
    "axs[3].legend(['Poet za챠zen챠'])\n",
    "\n",
    "# set x axis label for all plots\n",
    "axs[3].set_xlabel('as')\n",
    "# increase a font\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "\n",
    "# save plot with dpi 300\n",
    "plt.savefig('features_plot.pdf', dpi=300)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Yy1c-Q0pjab-"
   },
   "source": [
    "## Normalize the Data\n",
    "- for available scalers see: http://scikit-learn.org/stable/auto_examples/preprocessing/plot_all_scaling.html#sphx-glr-auto-examples-preprocessing-plot-all-scaling-py\n",
    "- becareful of outliers when scaling!\n",
    "- perform the normalization on the pandas dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r9Wi9R-njacI"
   },
   "source": [
    "## Use a data generator\n",
    "- creates batches on the fly\n",
    "- good for data with large number of rows and features\n",
    "- don't need to perform lags on dataframe\n",
    "- the function below was adapted from https://github.com/fchollet/deep-learning-with-python-notebooks/blob/master/6.3-advanced-usage-of-recurrent-neural-networks.ipynb\n",
    "- note: Keras added a TimeseriesGenerator class in version 2.1.5 \n",
    "    - https://github.com/keras-team/keras/releases/tag/2.1.5\n",
    "    - keras.preprocessing.sequence.TimeseriesGenerator\n",
    "keras.preprocessing.sequence.TimeseriesGenerator\n",
    "It yields a tuple `(samples, targets)` where `samples` is one batch of input data and \n",
    "`targets` is the corresponding array of target temperatures. It takes the following arguments:\n",
    "\n",
    "* `dataframe`: pandas dataframe with feature matrix and target column\n",
    "* `target_name`: string of column with target values\n",
    "* `lookback`: How many timesteps back should our input data go.\n",
    "* `delay`: How many timesteps in the future should our target be.\n",
    "* `min_index` and `max_index`: Indices in the `data` array that delimit which timesteps to draw from. This is useful for keeping a segment \n",
    "of the data for validation and another one for testing.\n",
    "* `shuffle`: Whether to shuffle our samples or draw them in chronological order.\n",
    "* `batch_size`: The number of samples per batch.\n",
    "* `step`: The period, in timesteps, at which we sample data. We will set it 6 in order to draw one data point every hour."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q289g6TtjacI"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k3V-ssIMjacN"
   },
   "source": [
    "## create train, validation, test data generators\n",
    "- we will 20% of the df_train to get the validation generator\n",
    "    - use the min_index,max_index arguments for slices from generator function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from pytz import utc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from data_handler import DataHandler\n",
    "from forecast import Forecast\n",
    "from datetime import datetime, timedelta\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# get nan values in df_train_form\n",
    "nan_values = df_train_form.isnull().sum()\n",
    "print(nan_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "def get_model(\n",
    "    df_train,\n",
    "    df_focused_train,\n",
    "    dataHandler,\n",
    "    predicted_columns,\n",
    "    model_path,\n",
    "    scaler_path,\n",
    "    train_on_all,\n",
    "    do_train,\n",
    "):\n",
    "\n",
    "    # use previous 450 samples to predict next target ('pollution') samples\n",
    "\n",
    "    start_of_data = datetime(2023, 10, 1, 0, 0, 0)\n",
    "    end_of_training_data = datetime(2024, 3, 16, 0, 0, 0)\n",
    "    forecast = Forecast(\n",
    "        dataHandler,\n",
    "        start_of_data=start_of_data,\n",
    "        model_path=model_path,\n",
    "        scaler_path=scaler_path,\n",
    "        predicted_columns=predicted_columns,\n",
    "    )\n",
    "    forecast.build_model()\n",
    "\n",
    "    if do_train:\n",
    "        if train_on_all:\n",
    "            forecast.train_model(df_training_data=df_train)\n",
    "        forecast.train_model(df_training_data=df_form)\n",
    "\n",
    "    forecast.load_model(\n",
    "\n",
    "    )\n",
    "    return forecast\n",
    "\n",
    "\n",
    "predicted_columns = [\n",
    "        \"longtime_mean\",\n",
    "]\n",
    "model_path_form = \"models/model_form_2.weights.h5\"\n",
    "scaler_path_form = \"pkl/scaler_form_2.pkl\"\n",
    "\n",
    "model_path_zuka = \"model_zuka_2.weights.h5\"\n",
    "scaler_path_zuka = \"scaler_zuka_2.pkl\"\n",
    "\n",
    "\n",
    "forecast = get_model(\n",
    "    df_train,\n",
    "    df_form,\n",
    "    dataHandlerForm,\n",
    "    predicted_columns,\n",
    "    model_path_form,\n",
    "    scaler_path_form,\n",
    "    train_on_all = True,\n",
    "    do_train=True,\n",
    ")\n",
    "\n",
    "\n",
    "df_test_norm = df_train_form.reset_index(drop=True).copy()\n",
    "df_test_direct = df_test_form\n",
    "\n",
    "\n",
    "forecast = get_model(\n",
    "    df_train,\n",
    "    df_train_zuka,\n",
    "    dataHandlerZuka,\n",
    "    predicted_columns,\n",
    "    model_path_zuka,\n",
    "    scaler_path_zuka,\n",
    "    train_on_all = True,\n",
    "    do_train=True,\n",
    ")\n",
    "df_test_norm = df_train_zuka.reset_index(drop=True).copy()\n",
    "df_test_direct = df_test_zuka\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "\n",
    "# df_test_norm = df_test_zuka.copy()\n",
    "df_test_norm[df_test_norm.columns] = forecast.scaler.transform(df_test_norm)\n",
    "\n",
    "\n",
    "\n",
    "df_test_norm = df_test_norm[-forecast.lookback*4:]\n",
    "test_gen = forecast.mul_generator(\n",
    "    dataframe=df_test_norm,\n",
    "    target_names=forecast.predicted_columns,\n",
    "    lookback=forecast.lookback,\n",
    "    delay=forecast.delay,\n",
    "    min_index=0,\n",
    "    max_index=None,\n",
    "    step=1,\n",
    "    shuffle=False,\n",
    "    batch_size=forecast.batch_size,\n",
    ")\n",
    "\n",
    "last_batch = next(test_gen)\n",
    "\n",
    "# Step 3: Extract the last batch of features (X_batch) and target values (y_truth_batch)\n",
    "(X_batch, y_truth) = last_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "X_df = pd.DataFrame(X_batch[0])\n",
    "X = pd.DataFrame(X_df.values.flatten()).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "feature_df = pd.DataFrame(columns=['feature','layer','neuron','weight','abs_weight'])\n",
    "features = [\"last_3_week_skew\",\"last_3_week_std\",\"distance_from_home\",\"speed_towards_home\",\"count\",\"heading_to_home_sin\",\"heading_to_home_cos\",\"temperature\",\"humidity\",\"wind_speed\",\"weekday_sin\",\"weekday_cos\",\"hour_sin\",\"hour_cos\",]\n",
    "\n",
    "for i,layer in enumerate(forecast.model.layers[:-1]): \n",
    "    w = layer.get_weights()\n",
    "    w = np.array(w[0])\n",
    "    n = 0\n",
    "    for neuron in w.T:\n",
    "        for f,name in zip(neuron,X.columns):\n",
    "            feature_df.loc[len(feature_df)] = [name,i,n,f,abs(f)]\n",
    "        \n",
    "        n+=1\n",
    "        \n",
    "feature_df = feature_df.sort_values(by=['abs_weight'])\n",
    "feature_df.reset_index(inplace=True)\n",
    "feature_df = feature_df.drop(['index'], axis=1)\n",
    "\n",
    "plt.bar(feature_df['feature'],feature_df['abs_weight'])\n",
    "plt.xticks(ticks=range(len(features)), labels=features, rotation=90)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "grouped_df = feature_df.groupby(['feature', 'neuron'])['weight'].sum().reset_index()\n",
    "# Plotting the bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "for neuron in grouped_df['neuron'].unique():\n",
    "    feature_data = grouped_df[grouped_df['neuron'] == neuron]\n",
    "    plt.bar(feature_data['feature'], feature_data['weight'], label=neuron) \n",
    "plt.xticks(ticks=range(len(features)), labels=features, rotation=90)\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Sum of absolute weights')\n",
    "plt.title('Sum of absolute weights for each feature in each neuron')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "grouped_df = feature_df.groupby(['feature', 'neuron'])['weight'].sum().reset_index()\n",
    "# Plotting the bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "for neuron in grouped_df['neuron'].unique():\n",
    "    feature_data = grouped_df[grouped_df['neuron'] == neuron]\n",
    "    plt.bar(feature_data['feature'], feature_data['weight'], label=neuron) \n",
    "plt.xticks(ticks=range(len(features)), labels=features, rotation=90)\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Sum of absolute weights')\n",
    "plt.title('Sum of absolute weights for each feature in each neuron')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "\n",
    "left_test = datetime(2023,12,30)\n",
    "right_test = datetime(2024,4,1)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# df_test_direct, _ = forecast.dataHandler.get_data_for_prediction(left_test, right_test)\n",
    "\n",
    "df_test_norm = df_test_direct.reset_index(drop=True).copy()\n",
    "\n",
    "# df_test_norm = df_test_zuka.copy()\n",
    "df_test_norm[df_test_norm.columns] = forecast.scaler.transform(df_test_norm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "test_gen = forecast.mul_generator(dataframe = df_test_norm, \n",
    "                     target_names = predicted_columns, \n",
    "                     lookback = forecast.lookback,\n",
    "                     delay = forecast.delay,\n",
    "                     min_index = 0,\n",
    "                     max_index = None,\n",
    "                     step = 1,\n",
    "                     shuffle = False,\n",
    "                     batch_size = df_test_norm.shape[0])\n",
    "(X, y_truth) = next(test_gen)\n",
    "# X_reshaped = X.reshape((X.shape[0], 1, X.shape[1]))\n",
    "\n",
    "y_pred = forecast.model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "num_targets = len(predicted_columns)\n",
    "len_columns = len(df_test_norm.columns)\n",
    "num_features = len_columns - num_targets\n",
    "\n",
    "\n",
    "# np.expand_dims(y_truth,axis=1).shape\n",
    "y_pred_inv = np.concatenate(\n",
    "    (y_pred, np.zeros((y_pred.shape[0], num_features))), axis=1\n",
    ")\n",
    "\n",
    "y_pred_inv = forecast.scaler.inverse_transform(y_pred_inv)\n",
    "\n",
    "y_truth_concat = np.concatenate(\n",
    "    (y_truth, np.zeros((y_truth.shape[0], num_features))), axis=1\n",
    ")\n",
    "y_truth_concat = forecast.scaler.inverse_transform(y_truth_concat)\n",
    "\n",
    "# create a dataframe from y_pred_inv and y_truth_concat\n",
    "y_pred_inv_df = pd.DataFrame(y_pred_inv, columns=df_test.columns)\n",
    "y_truth_concat_df = pd.DataFrame(y_truth_concat, columns=df_test.columns)\n",
    "\n",
    "y_pred_inv_df['truth'] = y_truth_concat_df['longtime_mean']\n",
    "y_pred_inv_df['longtime_mean'] = y_pred_inv_df['longtime_mean'].clip(lower=0.05)\n",
    "\n",
    "y_pred_inv_df = y_pred_inv_df.dropna()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YifTrpIhjacP"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(num_targets):\n",
    "    \n",
    "    datetime_start = datetime(2024, 3, 14, 0, 0, 0)\n",
    "    datetime_end = datetime_start + timedelta(hours=167)\n",
    "    datetime_range = pd.date_range(datetime_start, datetime_end, freq='H')\n",
    "    j = 100\n",
    "    plt.figure()\n",
    "    y_plot = y_pred_inv_df.copy()\n",
    "    y_plot = y_plot[j:j+2*168].reset_index(drop=True)\n",
    "    # y_plot = y_plot[:].reset_index(drop=True)\n",
    "    y_evaluate = y_plot.copy()\n",
    "    weeks_range = range(0, len(y_plot.index), 1)\n",
    "    plt.plot(weeks_range,y_plot['truth'], label=f'Skuten찼 spoteba [kWh]', alpha=1,color='#e23838' )\n",
    "    plt.plot(weeks_range,y_plot['longtime_mean'], label=f'Predikovan찼 spoteba [kWh]', alpha=1, color='#009cdf')\n",
    "    # set axis labels\n",
    "    mape = np.mean(np.abs((y_pred_inv_df['truth'] - y_pred_inv_df['longtime_mean']) / y_pred_inv_df['truth'])) * 100\n",
    "    \n",
    "    # plt.title(f'Prediction and real consumption of heat from boiler')\n",
    "    # plt.title(f'Predikovan찼 a skuten찼 hodinov찼 spoteba tepla z bojleru')\n",
    "    plt.xlabel('Time [h]')\n",
    "    plt.xlabel('as [h]')\n",
    "    plt.xticks(rotation=0)\n",
    "    plt.ylabel('Hourly comsumption [Wh]')\n",
    "    plt.ylabel('Hodinov찼 spoteba [Wh]')\n",
    "    plt.legend()\n",
    "    plt.savefig(f'prediction_form.pdf', format='pdf', dpi=500)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    # save fig as vector png\n",
    "    \n",
    "    # save as pdf\n",
    "    # slope, intercept, r_value, p_value, std_err = stats.linregress(x=y_pred_inv_df['longtime_mean'],y=y_pred_inv_df['truth'])\n",
    "    r2 = np.corrcoef(y_pred_inv_df['truth'], y_pred_inv_df['longtime_mean'])[0, 1] ** 2\n",
    "    mse = mean_squared_error(y_true=y_pred_inv_df['truth'], y_pred=y_pred_inv_df['longtime_mean'], squared=True)\n",
    "    rmse = mean_squared_error(y_true=y_pred_inv_df['truth'], y_pred=y_pred_inv_df['longtime_mean'], squared=False)\n",
    "\n",
    "\n",
    "    print('R2 = ',r2)\n",
    "    print('mse = ',mse)\n",
    "    print('rmse = ',rmse)\n",
    "    #print integral of y_pred_curr - y_truth_curr\n",
    "    print('integral delta = ',np.trapz(y_pred_inv_df['truth'] - y_pred_inv_df['longtime_mean']))\n",
    "    print('integral_truth = ',np.trapz(y_pred_inv_df['truth']))\n",
    "    print('integral_pred = ',np.trapz(y_pred_inv_df['longtime_mean']))\n",
    "    \n",
    "    # print percentual differece between integral of y_pred_curr - y_truth_curr and integral_truth\n",
    "    print('integral delta percentual = ',np.trapz(y_pred_inv_df['longtime_mean'] - y_pred_inv_df['truth'])/np.trapz(y_pred_inv_df['truth']))\n",
    "    print('mape:', mape)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "def custom_evaluation(df):\n",
    "    # Count the number of instances where actual is non-zero\n",
    "    non_zero_count = df[df['truth'] > 0.1].shape[0]\n",
    "    \n",
    "    # Calculate absolute error for each prediction\n",
    "    absolute_errors = np.abs(df['truth'] - df['longtime_mean'])\n",
    "    \n",
    "    # Calculate the mean absolute error for non-zero instances\n",
    "    if non_zero_count > 0:\n",
    "        mean_absolute_error_non_zero = np.sum(absolute_errors[df['truth'] > 0.1]) / non_zero_count\n",
    "    else:\n",
    "        mean_absolute_error_non_zero = 0  # Handle case where there are no non-zero instances\n",
    "    \n",
    "    # Calculate the overall mean absolute error\n",
    "    mean_absolute_error = np.mean(absolute_errors)\n",
    "    \n",
    "    # Weighted mean absolute error to give more importance to non-zero instances\n",
    "    custom_metric = 0.8 * mean_absolute_error + 0.2 * mean_absolute_error_non_zero\n",
    "    \n",
    "    return custom_metric\n",
    "\n",
    "custom_evaluation_result = custom_evaluation(y_evaluate)\n",
    "print(custom_evaluation_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "\n",
    "from pytz import utc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from data_handler import DataHandler\n",
    "from forecast import Forecast\n",
    "from datetime import datetime, timedelta\n",
    "start_of_data = datetime(2023, 11, 1)\n",
    "end_of_data = datetime(2023, 12, 10)\n",
    "end_of_training_data = datetime(2023, 12, 31, 0, 0, 0)\n",
    "dataHandler = DataHandler(\n",
    "    \"localhost\",\n",
    "    \"smart_home_zukalovi\",\n",
    "    \"root\",\n",
    "    \"root\",\n",
    "    \"shelly1pm_84cca8b07eae\",\n",
    "    \"shelly1pm_84cca8b07eae_power\",\n",
    "    \"esphome_web_c771e8_tmp3\",\n",
    "    \"esphome_web_c771e8_ntc_temperature_b_constant\",\n",
    "    \"esphome_web_c771e8_ntc_temperature_b_constant_2\",\n",
    "    device_tracker_entity_id=\"klara_z_iphone\",\n",
    "    device_tracker_entity_id_2=\"klara_z_iphone\",\n",
    "    home_longitude=49.412897925874184,\n",
    "home_latitude=16.514843458109933,\n",
    "start_of_data=start_of_data,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w9FLFXkvjacb"
   },
   "source": [
    "## Create LSTM model\n",
    "- to increase the modeling speed, replace the LSTM model with CuDNNLSTM and train on a GPU\n",
    "- can also use lightwieght GRU layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iZknUNitjach"
   },
   "source": [
    "## Fit the Model\n",
    "- to increase the modeling speed, replace the LSTM model with CuDNNLSTM and train on a GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q_Rt3pdsjacl"
   },
   "source": [
    "## Get model predictions on df_test\n",
    "- get (X,y_truth) by calling train_gen using next\n",
    "- set the batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "model = load_model('lstm_model_mul_var.keras', custom_objects={'r2_keras': r2_keras})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "df_test_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J-6pPDV0jacq"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# append a value to all rows in longtimemean column zeroes\n",
    "\n",
    "test_gen = forecast.mul_generator(dataframe = df_test_norm, \n",
    "                      target_names = predicted_columns, \n",
    "                     lookback = lookback,\n",
    "                     delay = delay,\n",
    "                     min_index = 0,\n",
    "                     max_index = None,\n",
    "                     step = 1,\n",
    "                     shuffle = False,\n",
    "                     batch_size = df_test.shape[0])\n",
    "(X, y_truth) = next(test_gen)\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "num_targets = len(predicted_columns)\n",
    "len_columns = len(df_test.columns)\n",
    "num_features = len_columns - num_targets\n",
    "\n",
    "# np.expand_dims(y_truth,axis=1).shape\n",
    "y_pred_inv = np.concatenate(\n",
    "    (y_pred, np.zeros((y_pred.shape[0], num_features))), axis=1\n",
    ")\n",
    "y_pred_inv = scaler.inverse_transform(y_pred_inv)\n",
    "\n",
    "y_truth = np.concatenate(\n",
    "    (y_truth, np.zeros((y_truth.shape[0], num_features))), axis=1\n",
    ")\n",
    "y_truth = scaler.inverse_transform(y_truth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "y_pred_abs = np.abs(y_pred_inv) - 0.2\n",
    "for i in range(num_targets):\n",
    "    plt.figure()\n",
    "    plt.plot(y_truth[:, i], label=f'True {predicted_columns[i]}')\n",
    "    plt.plot(y_pred_abs[:, i], label=f'Predicted {predicted_columns[i]}')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    y_pred_curr = y_pred_abs[:48, i]\n",
    "    y_truth_curr = y_truth[:48, i]\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(x=y_pred_curr,y=y_truth_curr)\n",
    "    mse = mean_squared_error(y_true=y_truth_curr, y_pred=y_pred_curr, squared=True)\n",
    "    rmse = mean_squared_error(y_true=y_truth_curr, y_pred=y_pred_curr, squared=False)\n",
    "\n",
    "\n",
    "    print('R2 = ',r_value*r_value)\n",
    "    print('mse = ',mse)\n",
    "    print('rmse = ',rmse)\n",
    "    #print integral of y_pred_curr - y_truth_curr\n",
    "    print('integral = ',np.trapz(y_pred_curr - y_truth_curr))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from datetime import timedelta, datetime\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "def add_empty_row(df, date_time):\n",
    "    new_row_df = pd.DataFrame(\n",
    "        columns=df.columns,\n",
    "        data=[\n",
    "            [\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                np.sin(2 * np.pi * date_time.weekday() / 7),\n",
    "                np.cos(2 * np.pi * date_time.weekday() / 7),\n",
    "                np.sin(2 * np.pi * date_time.hour / 24),\n",
    "                np.cos(2 * np.pi * date_time.hour / 24),\n",
    "                np.sin(2 * np.pi * date_time.minute / 60),\n",
    "                np.cos(2 * np.pi * date_time.minute / 60),\n",
    "            ]\n",
    "        ],\n",
    "    )\n",
    "    df = pd.concat([df, new_row_df], ignore_index=True)\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def get_forecast_next_steps(left_time_interval, right_time_interval):\n",
    "    # Define the indices for the different predictions and truths\n",
    "\n",
    "    num_targets = len(predicted_columns)\n",
    "    len_columns = len(df_test.columns)\n",
    "\n",
    "\n",
    "    forecast_future = pd.DataFrame()\n",
    "\n",
    "    df_all = dataHandler.get_data_for_prediction(\n",
    "        left_time_interval=left_time_interval,\n",
    "        right_time_interval=right_time_interval,\n",
    "        predicted_columns=predicted_columns,\n",
    "    )\n",
    "    df_all = df_all.dropna()\n",
    "    df_all = df_all.reset_index(drop=True)\n",
    "    forecast_future = pd.DataFrame()\n",
    "\n",
    "    current_forecast_begin_date = right_time_interval + timedelta(hours=0.5)\n",
    "    \n",
    "    df_all = add_empty_row(df_all, current_forecast_begin_date)\n",
    "    \n",
    "    current_forecast_begin_date += timedelta(hours=0.5)\n",
    "\n",
    "    # prediction for next 6 hours\n",
    "    for i in range(0, 12):\n",
    "        df_all = add_empty_row(df_all, current_forecast_begin_date)\n",
    "        current_forecast_begin_date += timedelta(hours=0.5)\n",
    "\n",
    "        df_predict_norm = df_all.copy()\n",
    "\n",
    "        df_predict_norm[df_all.columns] = scaler.transform(df_all)\n",
    "        # create predict df with values\n",
    "        predict_gen = mul_generator(\n",
    "            dataframe=df_predict_norm,\n",
    "            target_names=predicted_columns,\n",
    "            lookback=lookback,\n",
    "            delay=delay,\n",
    "            min_index=0,\n",
    "            max_index=None,\n",
    "            step=1,\n",
    "            shuffle=False,\n",
    "            batch_size=df_predict_norm.shape[0],\n",
    "        )\n",
    "\n",
    "        (X, y_truth) = next(predict_gen)\n",
    "\n",
    "        y_pred = model.predict(X, verbose=0)\n",
    "        # np.expand_dims(y_truth,axis=1).shape\n",
    "        y_pred_inv = np.concatenate(\n",
    "            (y_pred, np.zeros((y_pred.shape[0], len_columns-num_targets))), axis=1\n",
    "        )\n",
    "        y_pred_inv = scaler.inverse_transform(y_pred_inv)\n",
    "        # get last predicted value\n",
    "        y_pred_inv = y_pred_inv[-1, :]\n",
    "\n",
    "        # append y_pred_inv to df_all\n",
    "        df_all.iloc[-2,:num_targets] = y_pred_inv[:num_targets]\n",
    "        # drop first row\n",
    "        df_all = df_all[1:]\n",
    "\n",
    "        forecast_future = pd.concat(\n",
    "            [\n",
    "                forecast_future,\n",
    "                df_all.iloc[-2][:num_targets],\n",
    "            ],\n",
    "            axis=0,\n",
    "        )\n",
    "        forecast_future = forecast_future.reset_index(drop=True)\n",
    "        \n",
    "\n",
    "    return forecast_future, df_all\n",
    "\n",
    "# last 48 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "\n",
    "one_week_prediction = []\n",
    "number_of_30_minutes = 14*24*2\n",
    "end_train = datetime(2023,12,29, 0, 0, 0)\n",
    "start_of_data_loader_for_forecast = end_train\n",
    "end_of_data_loader_for_forecast = end_train + timedelta(hours=48)\n",
    "\n",
    "\n",
    "for i in range(0, number_of_30_minutes):\n",
    "    next_steps, _ = get_forecast_next_steps(left_time_interval=start_of_data_loader_for_forecast, right_time_interval=end_of_data_loader_for_forecast)\n",
    "    one_week_prediction.append(next_steps)\n",
    "    start_of_data_loader_for_forecast += timedelta(minutes=30)\n",
    "    end_of_data_loader_for_forecast += timedelta(minutes=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "df_truth = dataHandler.get_data_for_prediction(left_time_interval=end_train+timedelta(hours=48), right_time_interval=end_train+timedelta(hours=48)+timedelta(minutes=30*number_of_30_minutes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "list_df = []\n",
    "for df in one_week_prediction:\n",
    "    df_reshaped = (pd.DataFrame(np.reshape(df.values, (-1, 6)))).T\n",
    "    df_reshaped['prediction'] = [i for i in predicted_columns]\n",
    "\n",
    "    # transpose \n",
    "    list_df.append(df_reshaped)\n",
    "merged_df = pd.concat(list_df, ignore_index=True)\n",
    "merged_df['DataFrame_Order'] = [i for i in range(len(list_df)) for _ in range(6)]\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "longtime_mean = merged_df[merged_df['prediction'] == 'longtime_mean']\n",
    "distance_from_home = merged_df[merged_df['prediction'] == 'distance_from_home']\n",
    "speed_towards_home = merged_df[merged_df['prediction'] == 'speed_towards_home']\n",
    "count = merged_df[merged_df['prediction'] == 'count']\n",
    "heading_to_home_sin = merged_df[merged_df['prediction'] == 'heading_to_home_sin']\n",
    "heading_to_home_cos = merged_df[merged_df['prediction'] == 'heading_to_home_cos']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# shift the columns by -i\n",
    "shifted_df = merged_df.copy()\n",
    "for j in predicted_columns:\n",
    "    for i in range(0,12):\n",
    "        shifted_df.loc[shifted_df['prediction'] == j, i] = shifted_df.loc[shifted_df['prediction'] == j, i].shift(-i)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "#keep only columns from predicted columns\n",
    "data_truth = df_truth[predicted_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "result_df = shifted_df.copy()\n",
    "result_df['truth'] = 0  \n",
    "for prediction_column in predicted_columns:\n",
    "\n",
    "    for i in range(0,672):\n",
    "        result_df.loc[(result_df['prediction'] == prediction_column) & (result_df['DataFrame_Order'] == i), 'truth' ] = data_truth.loc[i, prediction_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "result_df = result_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "for predicted_column in predicted_columns:\n",
    "    number_of_steps = 1\n",
    "    #create a list of collors from 0 to 12 based on color\n",
    "    colors = plt.cm.viridis(np.linspace(0, 1, number_of_steps))\n",
    "    for i in range(0, number_of_steps):\n",
    "        plt.plot(result_df.loc[result_df['prediction']==predicted_column,i][:], label=f'predicted_{predicted_column}_{i}', color=colors[i], alpha=0.2)\n",
    "    # i =0\n",
    "    # plt.plot(df_shift[i], label=f'{i}_step_ahead')\n",
    "    plt.plot(result_df.loc[result_df['prediction'] == predicted_column,'truth'][:], label='truth')\n",
    "    plt.legend()   \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ISUUZtfMjacz"
   },
   "source": [
    "### Need to remove normalization\n",
    "- since we preformed normlization transform on 7 cols of dataframe, we need to add dummy colums to preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IsWb1_Hojac3"
   },
   "source": [
    "### Get R2 for this prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "print(y_truth.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "print(y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "#plot y_truth and y_pred\n",
    "plt.plot(y_truth[0], color = 'red', label = 'Real data')\n",
    "\n",
    "plt.plot(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "lp5fVzFXjac4",
    "outputId": "3dfd642c-068c-44c2-cb44-baa29681ff50"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "colab_type": "code",
    "id": "dRn6j-5Vjac9",
    "outputId": "973429fa-d13b-4616-c6bc-dd4c8062bfad"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "colab_type": "code",
    "id": "gi4-BFd4jadC",
    "outputId": "a6b08730-8e2c-40f3-a222-7e591ef516e9"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "\n",
    "plt.plot(y_truth, color = 'red', linestyle='dotted')\n",
    "plt.plot(y_pred, color = 'blue', linestyle='dotted')\n",
    "# change x ticks to dates\n",
    "print(np.arange(0, df_test.shape[0], step=24))\n",
    "# create list of dates by 1 hour from 2023-11-01 00:00:00 to 2023-11-30 23:00:00\n",
    "start = pd.to_datetime('2023-12-16 19:00:00')\n",
    "end = start + pd.Timedelta(hours=df_test.shape[0])\n",
    "dates = pd.date_range(start, end, freq='1H')\n",
    "\n",
    "# transform dates to format MM-DD HH\n",
    "dates = dates.strftime('%Y-%m-%d')\n",
    "# set xticks to dates\n",
    "plt.xticks(np.arange(0, df_test.shape[0], step=24), dates[np.arange(0, df_test.shape[0], step=24)], rotation=45)\n",
    "\n",
    "#add legend\n",
    "plt.legend(['skutenost','predikce'])\n",
    "\n",
    "# add x and y label\n",
    "plt.xlabel('Datum')\n",
    "plt.ylabel('Spoteba tepla [kJ]')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f0h37CyIjadH"
   },
   "source": [
    "## Let's try the evaluate_generator in keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "pQsfYFgcjadH",
    "outputId": "6bcc04f0-c1f7-4dd5-ce41-bd69f9534416"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "(_,r2) = model.evaluate_generator(generator=test_gen,steps=1,workers=1)\n",
    "print('R2 = ',r2)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "LSTM_test_with_multivariate_time_series.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
